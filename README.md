# **README.md**

```markdown
# OmniProt: Proteome-Encoded Growth Prediction Framework for *Rhodopseudomonas palustris* CGA009

OmniProt is an analytical framework integrating label-free quantitative proteomics with cross-condition machine learning to predict microbial growth outcomes and resolve a mechanistic hierarchy of proteome-encoded growth determinants.  

This repository accompanies the manuscript:

**â€œMachine Learning Resolves Proteome-Encoded Growth Predictors of *Rhodopseudomonas palustris* CGA009 on Lignin Aromatics.â€**

---

## ğŸ”¬ Scientific Summary

Microbial utilization of lignin-derived aromatics requires extensive metabolic flexibility, yet the quantitative determinants of growth variation remain unclear. OmniProt tests whether growth rates across diverse lignin substrates and oxygen regimes can be predicted directly from proteome composition.

The workflow delivers:

- Neural growth prediction across 16 substrateâ€“oxygen combinations  
- Cross-condition LOOCV performance benchmarking  
- Monte-Carlo SHAP feature attribution  
- Dependence-aware clustering to remove redundancy  
- A hierarchical determinant structure resolving conserved core vs. adaptive modulators  
- Publication-figures and visualizations for interpretation  

---

## ğŸ“ Repository Structure

```

OmniProt/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ proteomics_data.xlsx
â”‚   â”œâ”€â”€ GR_comparison.csv
â”‚   â”œâ”€â”€ kegg_mapper_result.txt
â”‚   â”œâ”€â”€ Kegg2Accession_pathway.xlsx
â”‚   â””â”€â”€ arial.ttf
â”‚
â”œâ”€â”€ growth_curve_fits/
â”‚
â”œâ”€â”€ results/                      # Auto-generated after pipeline run
â”‚   â””â”€â”€ data/
â”‚       
â”‚
â”œâ”€â”€ figures/               	  # To be Generated by analysis notebooks
â”‚	
â”œâ”€â”€ run_pipeline_1.py             # Full ML + SHAP pipeline
â”œâ”€â”€ functions_repo.py             # Model utilities and helper functions
â”œâ”€â”€ Analyze_Results_and_PlotFigures.ipynb
â”œâ”€â”€ HyperParameterTuning.ipynb
â”œâ”€â”€ OmniProt.yml                  # Conda environment file
â”‚
â””â”€â”€ submit_batch_job.sh           # SLURM execution script

````

---

## ğŸ“Š Input Files (`data/`)

| Filename | Description |
|---------|-------------|
| `proteomics_data.xlsx` | LFQ proteomics abundance matrix + sample metadata |
| `GR_comparison.csv` | Growth rate comparison metadata across conditions |
| `kegg_mapper_result.txt` | KEGG pathway mapper text output |
| `Kegg2Accession_pathway.xlsx` | KEGG â†’ UniProt â†’ pathway label mapping |
| `arial.ttf` | Font file used to produce journal-grade figures |

---

## ğŸ”„ Data â†’ Model â†’ Output Flow

**Main inputs defined in code:**

```python
ProteomicsDataFile = "data/proteomics_data.xlsx"
Kegg2UniprotFile   = "data/Kegg2Accession_pathway.xlsx"
````

During execution the following directories are created:

```
results/
results/data/
results/data/figures/
```

**Primary outputs include:**

* `results/output.xlsx` â†’ summary prediction table
* `results/data/SHAP_importance_mc_proteomics_Anchor_1.xlsx`
* `results/data/shap_resultsWithAnchorPR_1a.pkl.gz`
* `results/data/AP_SHAP_clusters_and_importance_proteomics_1.xlsx`
* `results/data/per_feature_rankings_by_cluster_proteomics_allOthers_1.xlsx`
* `results/data/cluster_members_PR_1.xlsx`
* `results/data/figures/` â†’ all visual outputs

---

## ğŸš€ Running the Pipeline Locally

### 1ï¸âƒ£ Create environment

```bash
conda env create -f OmniProt.yml
conda activate OmniProt
```

### 2ï¸âƒ£ Run OmniProt

```bash
python run_pipeline_1.py
```

This performs:

* training across 16 conditions
* condition-anchored LOOCV
* SHAP importance calculation
* tier and redundancy analysis
* result file export

---

## ğŸ§  Figure Generation

Manuscript-ready figures are produced with:

```bash
python Analyze_Results_and_PlotFigures.py
```

This script:

* loads post-pipeline SHAP & cluster results
* applies journal-style figure formatting (Arial, tick direction, spine thickness)
* exports PCA plots, tier barplots, and comparison figures to:

```
results/data/figures/
```

It also includes KEGG pathway parsing functionality that maps RPA genes to KEGG annotations from:

```
data/kegg_mapper_result.txt
```

---

## ğŸ–¥ï¸ HPC Execution (SLURM)

The repository includes a SLURM submission template:

```
submit_batch_job.sh
```

Example usage:

```bash
sbatch submit_batch_job.sh
```

The file requests:

* 2Ã— V100 GPUs
* 20 CPU tasks
* 60 GB RAM
* 168 hr max runtime

This configuration matches the runtime required for full lignin dataset processing (24â€“48 hr typical GPU runtime).

---

## ğŸ“š Notebook Utilities

### `HyperParameterTuning.ipynb`

* tuning via Optuna sweeps
* depth/width dropout search
* GPU-supported training

### `Analyze_Results_and_PlotFigures.py`

* growth comparison plots
* tier bar plots
* pathway annotation exports

---

## âš™ï¸ Dependencies

Environment specification lives in:

```
OmniProt.yml
```

Major libraries:

* Python â‰¥3.10
* pytorch
* numpy / pandas / scipy
* shap
* scikit-learn
* matplotlib / seaborn
* optuna

---


## ğŸ§¾ License

MIT License â€” open academic reuse permitted.

---

## âœ‰ï¸ Contact

For questions / collaboration:
**Abraham Osinuga**
University of Nebraskaâ€“Lincoln
Email: [aosinuga2@huskers.unl.edu](mailto:aosinuga2@huskers.unl.edu)
